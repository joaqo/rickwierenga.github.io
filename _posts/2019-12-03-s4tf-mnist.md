---
layout: post
title: Your first Swift for TensorFlow model
category: s4tf
---

Swift for TensorFlow is TensorFlow, implemented in Swift. Its Python counterpart ("TensorFlow") is one of the best deep learning libraries ever made, but it's hitting its limits. Python, being interpreted, is quite a slow language. Python is also limiting in many other ways, it lacks features that could make your life, as a programmer, much easier. 

So the TensorFlow team started looking for a better alternative. They chose Swift: a new, open source programming language originally developed by Apple, with a great focus on speed and readability. So here we are, Swift for TensorFlow is in the making. Even though the library lacks many features at this point, it is useable already. 

In this post I would like to show you how to build a perceptron and a convolutional neural network using this fancy new framework.

If you do not already know Swift, you will be surprised by the sheer amount of high quality learning resources available. The best place to start is [the swift website](https://www.swift.org). On the website, you will find [a complete book to learn the language](https://docs.swift.org/swift-book/index.html). The Swift for TensorFlow (S4TF) project is an extension of the Swift programming language with many additional features, beyond just deep learning. [Here](https://www.tensorflow.org/swift/) is its homepage.

Getting started with S4TF can be done without any setup using Google Colab. Swift is not currently registered as a default kernel, so you should use [this](https://colab.research.google.com/github/tensorflow/swift/blob/master/notebooks/blank_swift.ipynb) empty notebook as a starting point when developing Swift for TensorFlow applications. 

## Downloading dependencies
In Colab we can easily import the following libraries, without any installation:

```swift
import TensorFlow
import Foundation
import FoundationNetworking
```

Since the Swift for deep learnign ecosystem, and the Swift ecosystem overall, is still very young there aren't many stable libraries for some tasks like plotting. So sometimes we have to fall back on the well-established Python libraries. Luckily, Swift has excellent supoprt for Python interop.

You can import any Python library, by first importing the Python module in Swift and then importing a library. We will use matplotlib for plotting graphs and numpy to store data we are sending to matplotlib.

```swift
import Python
let plt = Python.import("matplotlib.pylab")
let np = Python.import("numpy")
```

To use matplotlib inline, run the following code: ([make sure it's ran in a seperate cell](https://bugs.swift.org/browse/TF-183))

```swift
%include "EnableIPythonDisplay.swift"
IPythonDisplay.shell.enable_matplotlib("inline")
```

Google Colab currently uses a slightly outdated version of S4TF (0.5 vs 0.6) which means we can't use the fancy [swift-models](https://github.com/tensorflow/swift-models/tree/master/Datasets) library to load datasets. Luckily we can work around it by recreating the MNIST dataset implementation. The following code is copied from the swift-models repo. Don't worry too much about the specifics for now, though it is interesting to read Swift code written by Google engineers.

```swift
public struct LabeledExample: TensorGroup {
    public var label: Tensor<Int32>
    public var data: Tensor<Float>

    public init(label: Tensor<Int32>, data: Tensor<Float>) {
        self.label = label
        self.data = data
    }

    public init<C: RandomAccessCollection>(
        _handles: C
    ) where C.Element: _AnyTensorHandle {
        precondition(_handles.count == 2)
        let labelIndex = _handles.startIndex
        let dataIndex = _handles.index(labelIndex, offsetBy: 1)
        label = Tensor<Int32>(handle: TensorHandle<Int32>(handle: _handles[labelIndex]))
        data = Tensor<Float>(handle: TensorHandle<Float>(handle: _handles[dataIndex]))
    }
}

public struct DatasetUtilities {
    public static let currentWorkingDirectoryURL = URL(
        fileURLWithPath: FileManager.default.currentDirectoryPath)

    public static func fetchResource(
        filename: String,
        remoteRoot: URL,
        localStorageDirectory: URL = currentWorkingDirectoryURL
    ) -> Data {
        print("Loading resource: \(filename)")

        let resource = ResourceDefinition(
            filename: filename,
            remoteRoot: remoteRoot,
            localStorageDirectory: localStorageDirectory)

        let localURL = resource.localURL

        if !FileManager.default.fileExists(atPath: localURL.path) {
            print(
                "File does not exist locally at expected path: \(localURL.path) and must be fetched"
            )
            fetchFromRemoteAndSave(resource)
        }

        do {
            print("Loading local data at: \(localURL.path)")
            let data = try Data(contentsOf: localURL)
            print("Succesfully loaded resource: \(filename)")
            return data
        } catch {
            fatalError("Failed to contents of resource: \(localURL)")
        }
    }

    struct ResourceDefinition {
        let filename: String
        let remoteRoot: URL
        let localStorageDirectory: URL

        var localURL: URL {
            localStorageDirectory.appendingPathComponent(filename)
        }

        var remoteURL: URL {
            remoteRoot.appendingPathComponent(filename).appendingPathExtension("gz")
        }

        var archiveURL: URL {
            localURL.appendingPathExtension("gz")
        }
    }

    static func fetchFromRemoteAndSave(_ resource: ResourceDefinition) {
        let remoteLocation = resource.remoteURL
        let archiveLocation = resource.archiveURL

        do {
            print("Fetching URL: \(remoteLocation)...")
            let archiveData = try Data(contentsOf: remoteLocation)
            print("Writing fetched archive to: \(archiveLocation.path)")
            try archiveData.write(to: archiveLocation)
        } catch {
            fatalError("Failed to fetch and save resource with error: \(error)")
        }
        print("Archive saved to: \(archiveLocation.path)")

        extractArchive(for: resource)
    }

    static func extractArchive(for resource: ResourceDefinition) {
        print("Extracting archive...")

        let archivePath = resource.archiveURL.path

        #if os(macOS)
            let gunzipLocation = "/usr/bin/gunzip"
        #else
            let gunzipLocation = "/bin/gunzip"
        #endif

        let task = Process()
        task.executableURL = URL(fileURLWithPath: gunzipLocation)
        task.arguments = [archivePath]
        do {
            try task.run()
            task.waitUntilExit()
        } catch {
            fatalError("Failed to extract \(archivePath) with error: \(error)")
        }
    }
}

public struct MNIST {
    public let trainingDataset: Dataset<LabeledExample>
    public let testDataset: Dataset<LabeledExample>
    public let trainingExampleCount = 60000

    public init() {
        self.init(flattening: false, normalizing: false)
    }

    public init(
        flattening: Bool = false, normalizing: Bool = false,
        localStorageDirectory: URL = DatasetUtilities.currentWorkingDirectoryURL
    ) {
        self.trainingDataset = Dataset<LabeledExample>(
            elements: fetchDataset(
                localStorageDirectory: localStorageDirectory,
                imagesFilename: "train-images-idx3-ubyte",
                labelsFilename: "train-labels-idx1-ubyte",
                flattening: flattening,
                normalizing: normalizing))

        self.testDataset = Dataset<LabeledExample>(
            elements: fetchDataset(
                localStorageDirectory: localStorageDirectory,
                imagesFilename: "t10k-images-idx3-ubyte",
                labelsFilename: "t10k-labels-idx1-ubyte",
                flattening: flattening,
                normalizing: normalizing))
    }
}

fileprivate func fetchDataset(
    localStorageDirectory: URL,
    imagesFilename: String,
    labelsFilename: String,
    flattening: Bool,
    normalizing: Bool
) -> LabeledExample {
    guard let remoteRoot:URL = URL(string: "http://yann.lecun.com/exdb/mnist") else {
        fatalError("Failed to create MNST root url: http://yann.lecun.com/exdb/mnist")
    }

    let imagesData = DatasetUtilities.fetchResource(
        filename: imagesFilename,
        remoteRoot: remoteRoot,
        localStorageDirectory: localStorageDirectory)
    let labelsData = DatasetUtilities.fetchResource(
        filename: labelsFilename,
        remoteRoot: remoteRoot,
        localStorageDirectory: localStorageDirectory)

    let images = [UInt8](imagesData).dropFirst(16).map(Float.init)
    let labels = [UInt8](labelsData).dropFirst(8).map(Int32.init)

    let rowCount = labels.count
    let (imageWidth, imageHeight) = (28, 28)

    if flattening {
        var flattenedImages = Tensor(shape: [rowCount, imageHeight * imageWidth], scalars: images)
            / 255.0
        if normalizing {
            flattenedImages = flattenedImages * 2.0 - 1.0
        }
        return LabeledExample(label: Tensor(labels), data: flattenedImages)
    } else {
        return LabeledExample(
            label: Tensor(labels),
            data:
                Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)
                .transposed(withPermutations: [0, 2, 3, 1]) / 255  // NHWC
        )
    }
}
```

If Google Colab gets updated, you can use just the following:

```swift
%install-location $cwd/swift-install
%install '.package(url: "https://github.com/tensorflow/swift-models", .branch("tensorflow-0.6"))' Datasets
```

```swift
import Datasets
```

Brad Larson from the core team has [said](https://github.com/tensorflow/swift-models/issues/233) they are working on an update.

Now we can initialize an MNIST instance. The API will automatically normalize each image.

```swift
let mnist = MNIST(flattening: false, normalizing: true)
```

## Building a perceptron
We will first look at the simplest neural network: a one layer perceptron.

### Dense layers
Swift requires you to tell it what data type you want each layer's corresponding tensors' elements to be. Here we use Float. The input and output size are identical to almost every other deep learning library. The activation function is available as a closure, we cas pass onto the layer. Because a layer expects a closure for the activation argument, it's very easy to develop your activation functions.

```swift
Dense<Float>(inputSize: 28 * 28, outputSize: 300, activation: relu)
```

### Building a simple model
This is how you would define a model in Swift:

```swift
struct Model: Layer {
    var hiddenLayer = Dense<Float>(inputSize: 28 * 28, outputSize: 300, activation: relu)
    var outputLayer = Dense<Float>(inputSize: 300, outputSize: 10, activation: softmax)

    @differentiable
    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {
        return input.sequenced(through: hiddenLayer, outputLayer)
    }
}
```

The `callAsFunction` function will be called when we feed forward `input` through the neural network.

Now create an instance of `Model`:
```swift
var model = Model()
```

This needs to be a variable because it will be changed througout training.

## Training the network
We will use a batch size of 512 here because it's, in my experience, the fastest option we can use in Colab. We also set the test batches before we start training so we only have to do it once. I trained the model for 10 epochs, but feel free to change the `epochs` variable. Because we will use shuffled batches during training, we do not yet set the training batches.

```swift
let batchSize = 512
let epochs = 10
let testBatches = mnist.testDataset.batched(batchSize)
```

Next we need an optimizer. Optimizers are, like many things in S4TF, also structs. So we need to initialize one:

```swift
let optimizer = Adam(for: model)
```

Now we are ready to implement a training loop:

```swift
for epoch in 1...10 {
  ...
}
```

In this loop we want to do two things: 

1. Update the parameters
2. Evaluate the model and print out the results

### 1. Updating the parameters
When you are training a model in TensorFlow you should tell it. TensorFlow will automatically adapt to your current learning phase. For example, dropout will be applied during learning, but not during inference.

```swift
Context.local.learningPhase = .training
```

Next we grab a set of training batches--shuffled of course:

```swift
let trainingShuffled = mnist.trainingDataset.shuffled(sampleCount: mnist.trainingExampleCount, randomSeed: Int64(epoch))
```

Then we loop over the batches, calculating the gradient at each step. We can apply gradients by passing them, and a pointer to the model, to our optimizer.

```swift
for batch in trainingShuffled.batched(batchSize) {
    let (labels, images) = (batch.label, batch.data)
    let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in
        let logits = model(images)
        return softmaxCrossEntropy(logits: logits, labels: labels)
    }
    optimizer.update(&model, along: gradients)
}
```

That's it. Our model will learn now.

### 2. Evaluating the model
Sitting there and waiting for a model to finish training is boring. Sitting there and looking at the accuracy improving over time is fascinating though, so let's make that happen.

Because we want to inspect the model's training history after training, we declare to empty numpy arrays. Using numpy is the best option, because this data will only be used by matplotlib, another Python library.

```swift
var trainHistory = np.zeros(epochs)
var valHistory = np.zeros(epochs)
```

We first set the learning phase to inference. Then we loop over the training set and test set and accumulate the correct predictions. We also store the accuracy in the numpy arrays for later use. Since the accuracy is in Swift's `Float` type, but the numpy array expects `PythonObject`s, we have to convert the data. Finally, we print out the results.

```swift
Context.local.learningPhase = .inference

var correctTrainGuessCount = 0
var totalTrainGuessCount = 0
for batch in mnist.trainingDataset.batched(batchSize) {
    let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))
    let logits = model(images)
    let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels
    correctTrainGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())
    totalTrainGuessCount += batch.data.shape[0]
}
let trainAcc = Float(correctTrainGuessCount) / Float(totalTrainGuessCount)
trainHistory[epoch] = PythonObject(trainAcc)

var correctValGuessCount = 0
var totalValGuessCount = 0
for batch in testBatches {
    let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))
    let logits = model(images)
    let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels
    correctValGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())
    totalValGuessCount += batch.data.shape[0]
}
let valAcc = Float(correctValGuessCount) / Float(totalValGuessCount)
valHistory[epoch] = PythonObject(valAcc)

print("\(epoch) | Training accuracy: \(trainAcc) | Validation accuracy: \(valAcc)")
```

You can now run the training loop and see the model learn!

## Building a ConvNet
While perceptrons get a great accuracy on MNIST, we can do better using a convolutional neural network. Let's have a look at how to build one using Swift for TensorFlow.

### Convolutional Layers
The primary building block of convolutional neural networks are, well, convolutional layers. S4TF mirrors the TensorFlow API instead of the Keras API, so the syntax might seem odd to you at first. In Swift you pass the filter size, input dimensions, and number of filtesr all in one tuple. Padding is an `enum`, beautiful! Finally, you can just use relu as we've seen before. This convolutional layer has a filter size of 2 by 2, 1 input dimension (since MNIST is greyscale), and 32 filters.

```swift
Conv2D<Float>(
    filterShape: (2, 2, 1, 32),
    padding: .same,
    activation: relu
)
```

### MaxPooling and Dropout
MaxPooling and Dropout layers have very similar APIs to their Keras counterparts.

This is how you would define a MaxPooling layer with a $$2\times2$$ pool size and a slide of $$1 \times 1$$:

```swift
MaxPool2D<Float>(poolSize: (2, 2), strides: (1, 1))
```

In Swift you cannot omit the keywoard `probability` when defining Dropout layers. This ensures consitent code througout the notebook.

```swift
Dropout<Float>(probability: 0.25)
```

### Building the ConvNet
Let's see how to combine these layers into a fully functional ConvNet. We start with two convolutional layers. Take a look at their input dimensions. Then we use a MaxPooling layer to compress the output of the convolutions. After this block we use a dropout layer with a 25% probability of dropping out, to prevent overfitting.

Before we code the head of the network, we need to flatten the output so that it can be passed onto a dense layer. Then we define two dense layers, with 128 and 10 output nodes respectively. In between those, we use another dropout layer, this time with a 50% probability of dropping out.

```swift
struct Model: Layer {
    var flatten1 = Flatten<Float>()
    var conv1 = Conv2D<Float>(
      filterShape: (2, 2, 1, 32),
      padding: .same,
      activation: relu
    )
    var conv2 = Conv2D<Float>(
      filterShape: (3, 3, 32, 64),
      padding: .same,
      activation: relu
    )
    var maxPooling = MaxPool2D<Float>(poolSize: (2, 2), strides: (1, 1))
    var dropout1 = Dropout<Float>(probability: 0.25)

    var flatten2 = Flatten<Float>()
    var dense1 = Dense<Float>(inputSize: 27 * 27 * 64, outputSize: 128, activation: relu)
    var dropout2 = Dropout<Float>(probability: 0.5)
    var dense2 = Dense<Float>(inputSize: 128, outputSize: 10, activation: softmax)

    @differentiable
    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {
        return input
          .sequenced(through: conv1, conv2, maxPooling, dropout1)
          .sequenced(through: flatten2, dense1, dropout2, dense2)
    }
}
```

You can use the same traning loop we used before.

## Inspecting the results
Plotting the data is surprisingly easy since we did most of the work already.

```swift
plt.plot(trainHistory)
plt.title("Training History")
plt.show()
```

It's just like Python isn't it?

## Conclusion
As you've seen it's not too hard to build and train a neural network in Swift, but it's definitely harder than Python. In this case, that is. Swift has many more things to offer, and I'm sure we will see some great improvements over the next few months.

You can find the code here:

* [Perceptron Colab]()
* [ConvNet Colab]()

Be sure to star [the GitHub repo](https://github.com/rickwierenga/s4tf-notebooks) where I will add many more Notebooks in the future!

